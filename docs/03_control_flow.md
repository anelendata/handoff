## Control flow

The exchange rate application was a realistic application. It had a simple
linear workflow. handoff offers more advanced workflow logic.


### foreach

Sometimes, you want to run the same task with different configurations.
Once you produce a list of the configuration keys such as account ID for
some service, handoff can run for-each loop.

05_foreach project shows the structure of foreach control flow.
project.yml looks like:

```shell
> cat 05_foreach/project.yml
```

```shell
tasks:
- name: generate_files
  pipeline:
  - command: cat
    args: files/in.txt
  - foreach:
    - name: do_foreach_test
      pipeline:
      - command: touch
        args: "artifacts/out_{{ _line }}.txt"

- name: verify
  pipeline:
  - command: ls
    args: "artifacts/out_*.txt"
  - command: wc
    args: -l

```


The first task generate_files writes out a list of IDs (1, 2, 3, 4, 5).
Then the second command "foreach" receive each ID stored in _line variable.
Under foreach definition, a sub-task is defined to do the process for each
input.

The second task, verify, verifies the number of output files generated by
the for-each loop.

Now let's run:

```shell
> handoff run local -p 05_foreach -w workspace_05
```
```shell

Running run local in workspace_05 directory
Job started at 2020-12-28 08:03:34.507094
[2020-12-28 08:03:34,507] [    INFO] - Running pipeline generate_files - (operators.py:193)
[2020-12-28 08:03:34,509] [    INFO] - Running foreach loop - (operators.py:208)
[2020-12-28 08:03:34,511] [    INFO] - Running pipeline do_foreach_test_1 - (operators.py:193)
[2020-12-28 08:03:34,515] [    INFO] - Checking return code of pid 22019 - (operators.py:262)
[2020-12-28 08:03:34,518] [    INFO] - Running pipeline do_foreach_test_2 - (operators.py:193)
[2020-12-28 08:03:34,523] [    INFO] - Checking return code of pid 22023 - (operators.py:262)
[2020-12-28 08:03:34,523] [    INFO] - Running pipeline do_foreach_test_3 - (operators.py:193)
[2020-12-28 08:03:34,529] [    INFO] - Checking return code of pid 22026 - (operators.py:262)
.
.
.
[2020-12-28 08:03:34,530] [    INFO] - Running pipeline do_foreach_test_4 - (operators.py:193)
[2020-12-28 08:03:34,536] [    INFO] - Checking return code of pid 22032 - (operators.py:262)
[2020-12-28 08:03:34,537] [    INFO] - Running pipeline do_foreach_test_5 - (operators.py:193)
[2020-12-28 08:03:34,543] [    INFO] - Checking return code of pid 22035 - (operators.py:262)
[2020-12-28 08:03:34,545] [    INFO] - Checking return code of pid 22017 - (operators.py:262)
[2020-12-28 08:03:34,545] [    INFO] - Running pipeline verify - (operators.py:193)
[2020-12-28 08:03:34,555] [    INFO] - Checking return code of pid 22041 - (operators.py:262)
[2020-12-28 08:03:34,555] [    INFO] - Checking return code of pid 22043 - (operators.py:262)
Job ended at 2020-12-28 08:03:34.556852
Processed in 0:00:00.049758
```


You can verify that 5 output files are created:

```shell

-rw-rw-r-- 1 ubuntu ubuntu 0 Dec 28 08:03 workspace_05/artifacts/out_1.txt
-rw-rw-r-- 1 ubuntu ubuntu 0 Dec 28 08:03 workspace_05/artifacts/out_2.txt
-rw-rw-r-- 1 ubuntu ubuntu 0 Dec 28 08:03 workspace_05/artifacts/out_3.txt
-rw-rw-r-- 1 ubuntu ubuntu 0 Dec 28 08:03 workspace_05/artifacts/out_4.txt
-rw-rw-r-- 1 ubuntu ubuntu 0 Dec 28 08:03 workspace_05/artifacts/out_5.txt
```

### fork

Sometimes, you want to fork the pipeline. fork command can help you with it.

06_fork project shows an example of using fork as an extension to our previous
exchange rates project.

project.yml looks like:


```shell
> cat 06_fork/project.yml
```

```shell
version: 0.3
description: Fetch foreign exchange rates

installs:
- venv: tap
  command: pip install tap-exchangeratesapi
- venv: target
  command: pip install target-csv

vars:
- key: base_currency
  value: USD

tasks:
- name: fetch_exchange_rates
  description: Fetch exchange rates
  pipeline:
  - command: tap-exchangeratesapi
    args: --config files/tap-config.json
    venv: tap
  - fork:
    - name: wide-format
      pipeline:
      - command: target-csv
        args: --config files/target-config.json
        venv: target
    - name: long-format
      pipeline:
      - command: python3
        args: files/convert_to_long_format.py
      - command: target-csv
        args: --config files/target-config.json
        venv: target

deploy:
  cloud_provider: aws
  cloud_platform: fargate
  resource_group: handoff-etl
  container_image: xxxxxxxxv
  task: exchange-rates

schedule:
  target_id: 1
  cron: "0 0 * * ? *"
  envs: []

```


The difference from 04_install project is that there are two target-csv
running by forking the tap-exchangerates stdin. The first task of the fork
wide-format dumps CSV just like the previous example. It has the wide-format
with all the currencies listed as columns.

The second task long-format dumps CSV converts to a long format. The output
from the long-format task has date, symbol, and rates columns:

Let's verify. First install workpace:

```shell
> handoff workspace install -p 06_fork -w workspace_06
```
```shell

Requirement already satisfied: wheel in ./tap/lib/python3.6/site-packages (0.36.2)
Collecting tap-exchangeratesapi
  Using cached tap_exchangeratesapi-0.1.1-cp36-none-any.whl
Collecting backoff==1.3.2
  Using cached backoff-1.3.2-cp36-none-any.whl
Collecting requests==2.21.0
  Using cached requests-2.21.0-py2.py3-none-any.whl (57 kB)
Collecting singer-python==5.3.3
  Using cached singer_python-5.3.3-cp36-none-any.whl
Collecting jsonschema==2.6.0
.
.
.
  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)
Collecting pytzdata
  Using cached pytzdata-2020.1-py2.py3-none-any.whl (489 kB)
Collecting tzlocal
  Using cached tzlocal-2.1-py2.py3-none-any.whl (16 kB)
Collecting pytz
  Using cached pytz-2020.5-py2.py3-none-any.whl (510 kB)
Installing collected packages: six, pytz, tzlocal, pytzdata, python-dateutil, simplejson, pendulum, singer-python, jsonschema, target-csv
Successfully installed jsonschema-2.6.0 pendulum-1.2.0 python-dateutil-2.8.1 pytz-2020.5 pytzdata-2020.1 simplejson-3.11.1 singer-python-2.1.4 six-1.15.0 target-csv-0.3.0 tzlocal-2.1
sucess
```

Now let's run:

```shell
> handoff run local -p 06_fork -w workspace_06 -v start_date=$(date -I -d "-7 day")
```
```shell

Running run local in workspace_06 directory
Job started at 2020-12-28 08:03:50.005358
[2020-12-28 08:03:50,005] [    INFO] - Running pipeline fetch_exchange_rates - (operators.py:193)
[2020-12-28 08:03:50,008] [    INFO] - Forking the downstream... - (operators.py:216)
[2020-12-28 08:03:50,008] [    INFO] - Running pipeline wide-format - (operators.py:193)
[2020-12-28 08:03:50,018] [    INFO] - Running pipeline long-format - (operators.py:193)
[2020-12-28 08:03:50,808] [    INFO] - Checking return code of pid 22134 - (operators.py:262)
[2020-12-28 08:03:50,854] [    INFO] - Checking return code of pid 22138 - (operators.py:262)
[2020-12-28 08:03:50,855] [    INFO] - Checking return code of pid 22140 - (operators.py:262)
[2020-12-28 08:03:50,865] [    INFO] - Checking return code of pid 22133 - (operators.py:262)
```

The long format file looks like this:

```shell

date,symbol,rate
2020-12-21T00:00:00Z,CAD,1.2885895014
2020-12-21T00:00:00Z,HKD,7.7530600509
```


Now that we know how to develop and run the pipeline locally, we will gradually
start thinking about how to deploy this in the cloud *severlessly*.
We will learn how to save and fetch the configurations to the remote storage.
Before doing that, we will cover how to set up AWS account and profile in the
next section.

